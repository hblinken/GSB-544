{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_csv(\"C:/Users/hblin/OneDrive - Cal Poly/GSB 544/Kaggle/gsb-544-fall-2024-political-affiliations/CAH-201803-train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop([\"id_num\", \"political_affiliation\"], axis= 1)\n",
    "\n",
    "y= train[\"political_affiliation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"C:/Users/hblin/OneDrive - Cal Poly/GSB 544/Kaggle/gsb-544-fall-2024-political-affiliations/CAH-201803-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing step\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"dummify\", \n",
    "         OneHotEncoder(sparse_output=False, handle_unknown='ignore'),\n",
    "         make_column_selector(dtype_include=object)),\n",
    "        (\"standardize\", \n",
    "         StandardScaler(), \n",
    "         make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "def evaluate_grid_search(grid_search, X, y):\n",
    "    \"\"\"\n",
    "    This function performs grid search, evaluates the best model, and prints the results.\n",
    "\n",
    "    Parameters:\n",
    "    - grid_search: The GridSearchCV object that has been set up with the pipeline and parameter grid.\n",
    "    - X: The feature matrix.\n",
    "    - y: The target vector.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Suppress warnings only in this block\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", FitFailedWarning)\n",
    "        grid_search.fit(X, y)  # Perform GridSearchCV without warnings\n",
    "\n",
    "    # Output the best parameters and ROC-AUC score\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(f\"Best Cross-validated Metric: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Make predictions with the best estimator\n",
    "    y_pred = grid_search.best_estimator_.predict(X)\n",
    "\n",
    "    # Print the classification report and confusion matrix\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Politics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lgr__C': 1, 'lgr__class_weight': 'balanced', 'lgr__l1_ratio': 0.1, 'lgr__penalty': 'l1', 'lgr__solver': 'liblinear'}\n",
      "Best Cross-validated Metric: 0.6275\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Democrat       0.68      0.75      0.71        59\n",
      " Independent       0.65      0.59      0.62        56\n",
      "  Republican       0.79      0.78      0.79        54\n",
      "\n",
      "    accuracy                           0.70       169\n",
      "   macro avg       0.71      0.70      0.70       169\n",
      "weighted avg       0.70      0.70      0.70       169\n",
      "\n",
      "Confusion Matrix:\n",
      "[[44 12  3]\n",
      " [15 33  8]\n",
      " [ 6  6 42]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hblin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan 0.62156863        nan        nan        nan 0.62156863\n",
      "        nan        nan        nan 0.62156863        nan        nan\n",
      "        nan 0.62745098        nan        nan        nan 0.62745098\n",
      "        nan        nan        nan 0.62745098        nan        nan\n",
      "        nan 0.34919786        nan        nan        nan 0.34919786\n",
      "        nan        nan        nan 0.34919786        nan        nan\n",
      "        nan 0.34919786        nan        nan        nan 0.34919786\n",
      "        nan        nan        nan 0.34919786        nan        nan\n",
      "        nan 0.34919786        nan        nan        nan 0.34919786\n",
      "        nan        nan        nan 0.34919786        nan        nan\n",
      "        nan 0.34919786        nan        nan        nan 0.34919786\n",
      "        nan        nan        nan 0.34919786        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\hblin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"lgr__C\": (1,.01,.001),  # Regularization strength (covers a wider range)\n",
    "    \"lgr__penalty\": [\"l1\",\"none\"],  # Adding \"none\" to include no regularization\n",
    "    \"lgr__solver\": [\"lbfgs\", \"liblinear\"],  # Adding all solvers supported\n",
    "    \"lgr__class_weight\": [None, \"balanced\"],  # Adjust weights for imbalanced data\n",
    "    \"lgr__l1_ratio\": (.1, 0.001, 1),  # ElasticNet mix ratio (used with solver=\"saga\")\n",
    "}\n",
    "\n",
    "lgr_pipeline = Pipeline(\n",
    "    [(\"preprocessing\", ct),\n",
    "     (\"lgr\", LogisticRegression())]  # Default classifier\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    lgr_pipeline,\n",
    "    param_grid,\n",
    "    cv=5,  # Ensures proper class distribution\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "evaluate_grid_search(grid_search, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lgr__C': 1, 'lgr__class_weight': 'balanced', 'lgr__l1_ratio': 0.1, 'lgr__penalty': 'l2', 'lgr__solver': 'liblinear'}\n",
      "Best Cross-validated Metric: 0.6332\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Democrat       0.68      0.73      0.70        59\n",
      " Independent       0.67      0.64      0.65        56\n",
      "  Republican       0.81      0.78      0.79        54\n",
      "\n",
      "    accuracy                           0.72       169\n",
      "   macro avg       0.72      0.72      0.72       169\n",
      "weighted avg       0.72      0.72      0.72       169\n",
      "\n",
      "Confusion Matrix:\n",
      "[[43 13  3]\n",
      " [13 36  7]\n",
      " [ 7  5 42]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hblin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "fin_param_grid = {\n",
    "    \"lgr__C\": [1],  # Regularization strength\n",
    "    \"lgr__class_weight\": [\"balanced\"],  # Adjust weights based on class frequencies\n",
    "    \"lgr__l1_ratio\": [0.1],  # ElasticNet mixing parameter (only relevant if 'elasticnet' is used)\n",
    "    \"lgr__penalty\": [\"l2\"],\n",
    "    \"lgr__solver\": [\"liblinear\"]  # Solver\n",
    "}\n",
    "\n",
    "lgr_pipeline = Pipeline(\n",
    "    [(\"preprocessing\", ct),\n",
    "     (\"lgr\", LogisticRegression())]  # Default classifier\n",
    ")\n",
    "\n",
    "final_model_fit = GridSearchCV(\n",
    "    lgr_pipeline,\n",
    "    fin_param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "evaluate_grid_search(final_model_fit, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'dt__criterion': 'entropy', 'dt__max_depth': 5, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 4}\n",
      "Best Cross-validated Metric: 0.6157\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Democrat       0.72      0.83      0.77        59\n",
      " Independent       0.73      0.68      0.70        56\n",
      "  Republican       0.94      0.85      0.89        54\n",
      "\n",
      "    accuracy                           0.79       169\n",
      "   macro avg       0.80      0.79      0.79       169\n",
      "weighted avg       0.79      0.79      0.79       169\n",
      "\n",
      "Confusion Matrix:\n",
      "[[49  8  2]\n",
      " [17 38  1]\n",
      " [ 2  6 46]]\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"dt__max_depth\": list(range(3, 11)) + [None],  # Integer range from 3 to 10, plus None for no limit\n",
    "    \"dt__min_samples_split\": list(range(2, 21)),  # Integer range from 2 to 20\n",
    "    \"dt__min_samples_leaf\": list(range(1, 11)),   # Integer range from 1 to 10\n",
    "    \"dt__criterion\": [\"gini\", \"entropy\"]          # Keep these as discrete choices\n",
    "}\n",
    "\n",
    "# Define the pipeline with DecisionTreeClassifier\n",
    "dt_pipeline = Pipeline(\n",
    "    [(\"preprocessing\", ct),\n",
    "     (\"dt\", DecisionTreeClassifier())]\n",
    ")\n",
    "\n",
    "# Set up GridSearchCV for cross-validation and hyperparameter search\n",
    "grid_search = GridSearchCV(dt_pipeline, param_grid, cv=StratifiedKFold(n_splits=5), scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV with your data\n",
    "grid_search.fit(X, y)\n",
    "evaluate_grid_search(grid_search, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = pd.DataFrame(\n",
    "    {\"id_num\": test_data['id_num'],\n",
    "    \"political_affiliation_predicted\": final_model_fit.predict(test_data)}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hblin\\AppData\\Local\\Temp\\ipykernel_32352\\1427950668.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_clean['logSalePrice'] = np.log(train_clean['SalePrice'])\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"C:/Users/hblin/OneDrive - Cal Poly/GSB 544/Kaggle/gsb-544-fall-2024-house-prices/train_new.csv\")\n",
    "\n",
    "test = pd.read_csv(\"C:/Users/hblin/OneDrive - Cal Poly/GSB 544/Kaggle/gsb-544-fall-2024-house-prices/test_new.csv\")\n",
    "\n",
    "train_clean = train.dropna()\n",
    "\n",
    "train_clean['logSalePrice'] = np.log(train_clean['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_clean.drop([\"SalePrice\",'logSalePrice',\"PID\"], axis= 1)\n",
    "\n",
    "y = train_clean[\"logSalePrice\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing step\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"dummify\", \n",
    "         OneHotEncoder(sparse_output=False, handle_unknown='ignore'),\n",
    "         make_column_selector(dtype_include=object)),\n",
    "        (\"standardize\", \n",
    "         StandardScaler(), \n",
    "         make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ").set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 0.1386362024849966\n",
      "Cross-validated RMSE: 14518516687.974293\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_pipeline = Pipeline(\n",
    "  [(\"preprocessing\", ct), # Polynomial features before linear regression\n",
    "   (\"lr\", LinearRegression())]  # Linear regression after polynomial features\n",
    ")\n",
    "\n",
    "# Fit the model on the full dataset\n",
    "lr_pipeline_fit = lr_pipeline.fit(X, y)\n",
    "\n",
    "# Predict on the same data\n",
    "y_pred = lr_pipeline.predict(X)\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Linear Regression RMSE:\", rmse)\n",
    "\n",
    "# Perform cross-validation with negative RMSE scoring\n",
    "cross_val_rmse_neg = cross_val_score(lr_pipeline, X, y, cv=5, scoring='neg_root_mean_squared_error').mean()\n",
    "\n",
    "# Convert negative RMSE to positive RMSE\n",
    "cross_val_rmse = -cross_val_rmse_neg  # Make the RMSE positive\n",
    "print(f\"Cross-validated RMSE: {cross_val_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 0.13972939605407306\n",
      "Cross-validated RMSE: 0.15312559584145574\n"
     ]
    }
   ],
   "source": [
    "# Adjust the pipeline and fit the model\n",
    "lr_pipeline = Pipeline(\n",
    "    [(\"preprocessing\", ct),  # Preprocessing step\n",
    "     (\"lr\", Ridge(alpha=1))]  # Use Ridge regression to apply regularization\n",
    ")\n",
    "\n",
    "# Fit the model on the full dataset\n",
    "lr_pipeline_fit = lr_pipeline.fit(X, y)\n",
    "\n",
    "# Predict on the same data\n",
    "y_pred = lr_pipeline.predict(X)\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Linear Regression RMSE:\", rmse)\n",
    "\n",
    "# Perform cross-validation with negative RMSE scoring\n",
    "cross_val_rmse_neg = cross_val_score(lr_pipeline, X, y, cv=5, scoring='neg_root_mean_squared_error').mean()\n",
    "\n",
    "# Convert negative RMSE to positive RMSE\n",
    "cross_val_rmse = -cross_val_rmse_neg  # Make the RMSE positive\n",
    "print(f\"Cross-validated RMSE: {cross_val_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression RMSE: 0.12585915832380812\n",
      "Cross-validated RMSE: 0.14149225057728243\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def add_squared_feature(X):\n",
    "    X = X.copy()\n",
    "    X['gr_liv_area_squared'] = X['Gr Liv Area'] ** 2\n",
    "    X['TotRms_AbvGrd_squared'] = X['TotRms AbvGrd'] ** 2\n",
    "    return X\n",
    "\n",
    "# Define the transformation for the new squared feature\n",
    "square_transformer = FunctionTransformer(add_squared_feature)\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "ct = ColumnTransformer([\n",
    "    (\"dummify\", OneHotEncoder(sparse_output=False, handle_unknown='ignore'), make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", StandardScaler(), make_column_selector(dtype_include=np.number))\n",
    "], remainder=\"passthrough\").set_output(transform=\"pandas\")\n",
    "\n",
    "# Define the pipeline with the custom transformer and Ridge regression\n",
    "lr_pipeline = Pipeline([\n",
    "    (\"add_squared_feature\", square_transformer),  # Add squared feature step\n",
    "    (\"preprocessing\", ct),  # Preprocessing step\n",
    "    (\"lr\", Ridge())  # Use Ridge regression to apply regularization\n",
    "])\n",
    "\n",
    "# Fit the model on the full dataset\n",
    "lr_pipeline.fit(X, y)\n",
    "\n",
    "# Predict on the same data\n",
    "y_pred = lr_pipeline.predict(X)\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Ridge Regression RMSE:\", rmse)\n",
    "\n",
    "# Perform cross-validation with negative RMSE scoring\n",
    "cross_val_rmse_neg = cross_val_score(lr_pipeline, X, y, cv=5, scoring='neg_root_mean_squared_error').mean()\n",
    "\n",
    "# Convert negative RMSE to positive RMSE\n",
    "cross_val_rmse = -cross_val_rmse_neg  # Make the RMSE positive\n",
    "print(f\"Cross-validated RMSE: {cross_val_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression RMSE: 0.1258591671401557\n",
      "Cross-validated RMSE: 0.14149226662084133\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def add_squared_feature(X):\n",
    "    X = X.copy()\n",
    "    X['gr_liv_area_squared'] = X['Gr Liv Area'] ** 2\n",
    "    X['TotRms_AbvGrd_squared'] = X['TotRms AbvGrd'] ** 2\n",
    "    X['Yr Sold'] = X['Yr Sold'] ** 2\n",
    "    return X\n",
    "\n",
    "# Define the transformation for the new squared feature\n",
    "square_transformer = FunctionTransformer(add_squared_feature)\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "ct = ColumnTransformer([\n",
    "    (\"dummify\", OneHotEncoder(sparse_output=False, handle_unknown='ignore'), make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", StandardScaler(), make_column_selector(dtype_include=np.number))\n",
    "], remainder=\"passthrough\").set_output(transform=\"pandas\")\n",
    "\n",
    "# Define the pipeline with the custom transformer and Ridge regression\n",
    "lr_pipeline = Pipeline([\n",
    "    (\"add_squared_feature\", square_transformer),  # Add squared feature step\n",
    "    (\"preprocessing\", ct),  # Preprocessing step\n",
    "    (\"lr\", Ridge())  # Use Ridge regression to apply regularization\n",
    "])\n",
    "\n",
    "# Fit the model on the full dataset\n",
    "lr_pipeline.fit(X, y)\n",
    "\n",
    "# Predict on the same data\n",
    "y_pred = lr_pipeline.predict(X)\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Ridge Regression RMSE:\", rmse)\n",
    "\n",
    "# Perform cross-validation with negative RMSE scoring\n",
    "cross_val_rmse_neg = cross_val_score(lr_pipeline, X, y, cv=5, scoring='neg_root_mean_squared_error').mean()\n",
    "\n",
    "# Convert negative RMSE to positive RMSE\n",
    "cross_val_rmse = -cross_val_rmse_neg  # Make the RMSE positive\n",
    "print(f\"Cross-validated RMSE: {cross_val_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           PID      SalePrice\n",
      "0    907135180  129121.422430\n",
      "1    528181040  198669.734524\n",
      "2    528175010  202149.761402\n",
      "3    531379030  189110.857786\n",
      "4    923275090  134914.334307\n",
      "..         ...            ...\n",
      "600  528174060  185396.629606\n",
      "601  903400180  166333.109367\n",
      "602  903227150  142451.111832\n",
      "603  909250070  131226.847637\n",
      "604  909425180  212030.918876\n",
      "\n",
      "[605 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_predictions = grid_search.predict(test)\n",
    "\n",
    "# Create a DataFrame for the predictions\n",
    "predictions_df_2 = pd.DataFrame(test_predictions, columns=['SalePrice'])\n",
    "\n",
    "# Add the 'PID' variable from the test DataFrame\n",
    "predictions_df_2['PID'] = test['PID']\n",
    "\n",
    "# Exponentiate the Predicted_SalePrice\n",
    "predictions_df_2['SalePrice'] = np.exp(predictions_df_2['SalePrice'])\n",
    "\n",
    "# Reorder the columns so PID is first (optional)\n",
    "predictions_df_2 = predictions_df_2[['PID', 'SalePrice']]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(predictions_df_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression RMSE: 0.13817894042490236\n",
      "Cross-validated RMSE: 0.17555797075710075\n",
      "Best Parameters: {'knn__metric': 'manhattan', 'knn__n_neighbors': 5, 'knn__weights': 'distance'}\n",
      "Best Cross-validated RMSE: 0.1654955247080679\n"
     ]
    }
   ],
   "source": [
    "knn_pipeline = Pipeline(\n",
    "  [(\"add_squared_feature\", square_transformer),\n",
    "    (\"preprocessing\", ct),\n",
    "    (\"knn\", KNeighborsRegressor(n_neighbors=5))]\n",
    ")\n",
    "\n",
    "knn_pipeline.fit(X,y)\n",
    "\n",
    "y_pred = knn_pipeline.predict(X)\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Ridge Regression RMSE:\", rmse)\n",
    "\n",
    "# Perform cross-validation with negative RMSE scoring\n",
    "cross_val_rmse_neg = cross_val_score(knn_pipeline, X, y, cv=5, scoring='neg_root_mean_squared_error').mean()\n",
    "\n",
    "# Convert negative RMSE to positive RMSE\n",
    "cross_val_rmse = -cross_val_rmse_neg  # Make the RMSE positive\n",
    "print(f\"Cross-validated RMSE: {cross_val_rmse}\")\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [5],\n",
    "    'knn__weights': ['distance'],\n",
    "    'knn__metric': ['manhattan']\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(knn_pipeline, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best parameters and RMSE\n",
    "best_params = grid_search.best_params_\n",
    "best_rmse = -grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(f\"Best Cross-validated RMSE: {best_rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
